services:
  comfyui:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        # Pin ComfyUI to a known-good commit/tag if desired
        COMFYUI_REF: "${COMFYUI_REF:-master}"
        # SageAttention ref (e.g., "main", "v2.2.0", or specific commit)
        SAGEATTN_REF: "${SAGEATTN_REF:-main}"

    image: sparkyui:cu130
    container_name: comfyui

    # GPU enablement
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # LAN exposure
    ports:
      - "${COMFYUI_PORT:-8188}:8188"

    environment:
      COMFYUI_PORT: "${COMFYUI_PORT:-8188}"
      COMFYUI_FLAGS: "${COMFYUI_FLAGS:---listen 0.0.0.0 --port 8188 --gpu-only}"
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
      # Disable torch.compile/inductor - Triton doesn't support Blackwell sm_121a yet
      TORCH_COMPILE_DISABLE: "1"
      TORCHDYNAMO_DISABLE: "1"

    volumes:
      # Models from existing ComfyUI install (read-only)
      - ${COMFYUI_HOST_PATH}/models:/opt/ComfyUI/models:ro

      # Custom nodes - comment out to use container-only (fresh) custom_nodes
      # If mounted, ComfyUI-Manager installs persist across container restarts
      - ${SPARKYUI_DATA_PATH}/custom_nodes:/opt/ComfyUI/custom_nodes

      # Outputs/inputs/workflows - persistent across restarts
      - ${SPARKYUI_DATA_PATH}/output:/opt/ComfyUI/output
      - ${SPARKYUI_DATA_PATH}/input:/opt/ComfyUI/input
      - ${SPARKYUI_DATA_PATH}/workflows:/opt/ComfyUI/workflows

      # Wheel cache (optional - for prebuilt wheels)
      - ${SPARKYUI_DATA_PATH}/wheels:/opt/wheels

    restart: unless-stopped
